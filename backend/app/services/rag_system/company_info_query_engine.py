from langchain_openai import OpenAIEmbeddings  # OpenAIåµŒå…¥æ¨¡å‹
from langchain_community.vectorstores import FAISS  # å‘é‡æ•°æ®åº“
from langchain.prompts import PromptTemplate  # æç¤ºæ¨¡æ¿
from langchain_openai import ChatOpenAI  # OpenAIèŠå¤©æ¨¡å‹
from langchain.schema.runnable import RunnablePassthrough  # é“¾å¼å¤„ç†
from langchain.schema import StrOutputParser  # è¾“å‡ºè§£æ
from config_utils import load_openai_key  # åŠ è½½APIå¯†é’¥

# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
embeddings_model = OpenAIEmbeddings(openai_api_key=load_openai_key())

# åŠ è½½é¢„è®­ç»ƒçš„å‘é‡æ•°æ®åº“
with open('./tmp/faiss_vectorstore.pkl', 'rb') as f:
    vectorstore_bytes = f.read()
vectorstore = FAISS.deserialize_from_bytes(
    embeddings=embeddings_model, 
    serialized=vectorstore_bytes, 
    allow_dangerous_deserialization=True
)

# ğŸ”„ åˆ‡æ¢åˆ°æœ€ä¾¿å®œçš„gpt-3.5-turboæ¨¡å‹
llm = ChatOpenAI(
    model_name="gpt-3.5-turbo",  # âœ… ä»gpt-4oæ”¹ä¸ºgpt-3.5-turbo  
    openai_api_key=load_openai_key(),
    temperature=0.3,  # é€‚ä¸­çš„åˆ›é€ æ€§
    max_tokens=800,   # æ§åˆ¶è¾“å‡ºé•¿åº¦ï¼ŒèŠ‚çœè´¹ç”¨
    timeout=30        # è®¾ç½®è¶…æ—¶æ—¶é—´
)

# ä¼˜åŒ–çš„å›ç­”æ¨¡æ¿ - æ›´ç®€æ´æ˜ç¡®
template = """
You are a knowledgeable financial assistant specializing in company information and market trends. 
Use the following information to answer the user's question in a natural, conversational manner. 
Keep your response concise, accurate, and focused.

Context: {context}
User's question: {question}

Your Answer:"""

prompt = PromptTemplate.from_template(template)  # åˆ›å»ºæ¨¡æ¿å®ä¾‹

# æ„å»ºå¤„ç†é“¾
chain = (
    {"context": RunnablePassthrough(), "question": RunnablePassthrough()}
    | prompt  # åº”ç”¨æ¨¡æ¿
    | llm  # è°ƒç”¨æ¨¡å‹
    | StrOutputParser()  # è§£æè¾“å‡º
)

def run_general_query(query):
    """æ‰§è¡Œé€šç”¨æŸ¥è¯¢"""
    try:
        # å‘é‡ç›¸ä¼¼åº¦æœç´¢ï¼Œåªå–å‰3ä¸ªç»“æœä»¥æé«˜æ•ˆç‡
        results = vectorstore.similarity_search(query, k=3)  
        
        if not results:
            return "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„å…¬å¸ä¿¡æ¯ã€‚è¯·å°è¯•æ›´å…·ä½“çš„é—®é¢˜ã€‚"
        
        # åˆå¹¶å‰3ä¸ªç»“æœçš„å†…å®¹
        top_results_content = " ".join([result.page_content for result in results])
        
        # ç”Ÿæˆå›ç­”
        response = chain.invoke({"question": query, "context": top_results_content})
        return response
        
    except Exception as e:
        print(f"General query error: {str(e)}")
        return f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"

if __name__ == "__main__":
    # æµ‹è¯•æŸ¥è¯¢
    query = "What companies have a comparable business model to Microsoft?"
    response = run_general_query(query)
    print(response)